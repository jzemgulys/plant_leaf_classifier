{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65984d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#import os\n",
    "#os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd5c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9c93de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf_classif\\train\n"
     ]
    }
   ],
   "source": [
    "root = 'leaf_classif'\n",
    "print(os.path.join(root, 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "032083ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "files = [file for file in os.listdir(root) if os.path.isfile(os.path.join(root, file))]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c145fb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 412 validated image filenames belonging to 2 classes.\n",
      "Found 10 validated image filenames belonging to 2 classes.\n",
      "Found 10 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "main_dir = root  # Replace with your main directory\n",
    "\n",
    "def label_from_folder_name(folder_name):\n",
    "    if 'healthy' in folder_name:\n",
    "        return 'healthy'  # Class label for healthy images\n",
    "    elif 'diseased' in folder_name:\n",
    "        return 'diseased'  # Class label for unhealthy images\n",
    "    else:\n",
    "        return None  # No specific label found\n",
    "    \n",
    "def custom_flow_from_directory(directory, target_size, batch_size):\n",
    "    filenames = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "\n",
    "    for folder in os.listdir(directory):\n",
    "        # first 2 folders\n",
    "        if i > 1:\n",
    "            break\n",
    "        folder_path = os.path.join(directory, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                 for file in files:\n",
    "                     filenames.append(os.path.join(root, file))\n",
    "                     labels.append(label_from_folder_name(root))\n",
    "        i = i + 1\n",
    "\n",
    "    filenames = np.array(filenames)\n",
    "    labels = np.array(labels, dtype=str)  # Ensure labels are strings\n",
    "\n",
    "    return ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
    "        pd.DataFrame({\"filename\": filenames, \"class\": labels}),\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "# Use the custom function to load data\n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "train_dir = os.path.join(main_dir, 'train')\n",
    "test_dir = os.path.join(main_dir, 'test')\n",
    "valid_dir = os.path.join(main_dir, 'valid')\n",
    "\n",
    "train_generator = custom_flow_from_directory(train_dir, (img_height, img_width), batch_size)\n",
    "test_generator = custom_flow_from_directory(test_dir, (img_height, img_width), batch_size)\n",
    "valid_generator = custom_flow_from_directory(test_dir, (img_height, img_width), batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80cd6cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ba4942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 54s 4s/step - loss: 0.8039 - accuracy: 0.5510 - val_loss: 0.6877 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.6577 - accuracy: 0.5995 - val_loss: 0.6691 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.6223 - accuracy: 0.6650 - val_loss: 0.6047 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.5294 - accuracy: 0.7354 - val_loss: 0.3769 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.3946 - accuracy: 0.8544 - val_loss: 0.2008 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 55s 4s/step - loss: 0.4182 - accuracy: 0.8180 - val_loss: 0.6544 - val_accuracy: 0.6000\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 54s 4s/step - loss: 0.4149 - accuracy: 0.8495 - val_loss: 0.2428 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 54s 4s/step - loss: 0.3210 - accuracy: 0.8786 - val_loss: 0.5104 - val_accuracy: 0.7000\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.3761 - accuracy: 0.8422 - val_loss: 0.2818 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.2998 - accuracy: 0.8859 - val_loss: 0.1745 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Calculate steps_per_epoch and validation_steps\n",
    "steps_per_epoch_train = train_generator.samples // batch_size\n",
    "steps_per_epoch_valid = valid_generator.samples // batch_size\n",
    "steps_per_epoch_test = test_generator.samples // batch_size\n",
    "\n",
    "epochs = 10\n",
    "# Add 1 extra step if there are remaining samples not included in batches\n",
    "if train_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_train += 1\n",
    "if valid_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_valid += 1\n",
    "if test_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_test += 1\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=steps_per_epoch_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3c3cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.1745 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=steps_per_epoch_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b554f86e",
   "metadata": {
    "id": "AbwhUtUgq_16"
   },
   "source": [
    "Fine tune CNN model - doubling number of epochs to 20, reducing steps size by half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8de9312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.2392 - accuracy: 0.9045 - val_loss: 0.1066 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.3075 - accuracy: 0.8591 - val_loss: 0.1340 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2089 - accuracy: 0.9196 - val_loss: 0.1067 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2416 - accuracy: 0.9152 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.1544 - accuracy: 0.9598 - val_loss: 0.1737 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.1392 - accuracy: 0.9636 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.1203 - accuracy: 0.9682 - val_loss: 0.1506 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.1046 - accuracy: 0.9732 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0690 - accuracy: 0.9777 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0449 - accuracy: 0.9909 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.1040 - accuracy: 0.9545 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0822 - accuracy: 0.9643 - val_loss: 0.0911 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0601 - accuracy: 0.9821 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2290 - accuracy: 0.9091 - val_loss: 0.2333 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.2031 - accuracy: 0.8750 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.1652 - accuracy: 0.9227 - val_loss: 0.2423 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.1217 - accuracy: 0.9688 - val_loss: 0.1043 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.1044 - accuracy: 0.9821 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0291 - accuracy: 0.9955 - val_loss: 0.0412 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Calculate steps_per_epoch and validation_steps\n",
    "steps_per_epoch_train = train_generator.samples // (batch_size * 2)\n",
    "steps_per_epoch_valid = valid_generator.samples // (batch_size * 2)\n",
    "steps_per_epoch_test = test_generator.samples // (batch_size * 2)\n",
    "\n",
    "epochs = 20\n",
    "# Add 1 extra step if there are remaining samples not included in batches\n",
    "if train_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_train += 1\n",
    "if valid_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_valid += 1\n",
    "if test_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_test += 1\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=steps_per_epoch_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c921d8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0412 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=steps_per_epoch_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3cfd3",
   "metadata": {},
   "source": [
    "Use a model built from a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aed3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pretrained model\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define input image size expected by MobileNet\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Load the MobileNet model without the top classification layer\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze the layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom top layers for binary classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)  # Binary classification using sigmoid activation\n",
    "\n",
    "# Combine base model with custom top layers\n",
    "mobileModel = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "mobileModel.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fefa820b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 54s 4s/step - loss: 0.0290 - accuracy: 0.9927 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.0259 - accuracy: 0.9951 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 53s 4s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x245b1a21610>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "# Calculate steps_per_epoch and validation_steps\n",
    "steps_per_epoch_train = train_generator.samples // batch_size\n",
    "steps_per_epoch_valid = valid_generator.samples // batch_size\n",
    "epochs = 10\n",
    "# Add 1 extra step if there are remaining samples not included in batches\n",
    "if train_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_train += 1\n",
    "if valid_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_valid += 1\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=steps_per_epoch_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b50b4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.3134 - accuracy: 0.5000\n",
      "Test Loss: 1.3134\n",
      "Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "loss, accuracy = mobileModel.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e7e4bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 31s 4s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 30s 4s/step - loss: 9.1172e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 8.2134e-04 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 8.7130e-04 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 9.3733e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 7.1712e-04 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 6.0799e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 7.0530e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 6.5939e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 6.4182e-04 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 5.0892e-04 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 5.2332e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 5.4111e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 3.2906e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 3.9022e-04 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 30s 4s/step - loss: 4.7798e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 5.4107e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 29s 4s/step - loss: 3.8616e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Fine tune the pretrained model\n",
    "\n",
    "# Calculate steps_per_epoch and validation_steps\n",
    "steps_per_epoch_train = train_generator.samples // (batch_size * 2)\n",
    "steps_per_epoch_valid = valid_generator.samples // (batch_size * 2)\n",
    "epochs = 20\n",
    "# Add 1 extra step if there are remaining samples not included in batches\n",
    "if train_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_train += 1\n",
    "if valid_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_valid += 1\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=steps_per_epoch_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d13f9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 1.3134 - accuracy: 0.5000\n",
      "Test Loss: 1.3134\n",
      "Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "loss, accuracy = mobileModel.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
