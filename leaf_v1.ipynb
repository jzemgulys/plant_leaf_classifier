{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65984d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jerem\\anaconda3\\envs\\ai\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd5c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9c93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'leaf_classif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "032083ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir(root) if os.path.isfile(os.path.join(root, file))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c145fb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 validated image filenames belonging to 2 classes.\n",
      "Found 66 validated image filenames belonging to 2 classes.\n",
      "Found 66 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "main_dir = root  # Replace with your main directory\n",
    "\n",
    "def label_from_folder_name(folder_name):\n",
    "    if 'healthy' in folder_name:\n",
    "        return 'healthy'  # Class label for healthy images\n",
    "    elif 'diseased' in folder_name:\n",
    "        return 'diseased'  # Class label for unhealthy images\n",
    "    else:\n",
    "        return None  # No specific label found\n",
    "    \n",
    "def custom_flow_from_directory(directory, target_size, batch_size):\n",
    "    filenames = []\n",
    "    labels = []\n",
    "\n",
    "    for folder in os.listdir(directory):\n",
    "        folder_path = os.path.join(directory, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                # Randomly shuffle the list of files\n",
    "                random.shuffle(files)\n",
    "\n",
    "                # Take the first 3 files from the shuffled list\n",
    "                selected_files = files[:3]\n",
    "                for file in selected_files:\n",
    "                  filenames.append(os.path.join(root, file))\n",
    "                  labels.append(label_from_folder_name(root))\n",
    "\n",
    "    filenames = np.array(filenames)\n",
    "    labels = np.array(labels, dtype=str)  # Ensure labels are strings\n",
    "\n",
    "    return ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
    "        pd.DataFrame({\"filename\": filenames, \"class\": labels}),\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "# Use the custom function to load data\n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "train_dir = os.path.join(main_dir, 'train')\n",
    "test_dir = os.path.join(main_dir, 'test')\n",
    "valid_dir = os.path.join(main_dir, 'valid')\n",
    "\n",
    "train_generator = custom_flow_from_directory(train_dir, (img_height, img_width), batch_size)\n",
    "test_generator = custom_flow_from_directory(test_dir, (img_height, img_width), batch_size)\n",
    "valid_generator = custom_flow_from_directory(test_dir, (img_height, img_width), batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80cd6cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jerem\\anaconda3\\envs\\ai\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jerem\\anaconda3\\envs\\ai\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jerem\\anaconda3\\envs\\ai\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ba4942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\jerem\\anaconda3\\envs\\ai\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jerem\\anaconda3\\envs\\ai\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3/3 [==============================] - 84s 41s/step - loss: 0.7308 - accuracy: 0.5606 - val_loss: 0.7301 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 65s 25s/step - loss: 0.7397 - accuracy: 0.4394 - val_loss: 0.6917 - val_accuracy: 0.5606\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 4453s 2226s/step - loss: 0.7378 - accuracy: 0.5000 - val_loss: 0.7093 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 29s 14s/step - loss: 0.6845 - accuracy: 0.5303 - val_loss: 0.6947 - val_accuracy: 0.5152\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 29s 11s/step - loss: 0.6887 - accuracy: 0.5152 - val_loss: 0.6950 - val_accuracy: 0.5152\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 28s 10s/step - loss: 0.6798 - accuracy: 0.6970 - val_loss: 0.6951 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 17s 7s/step - loss: 0.7554 - accuracy: 0.5000 - val_loss: 0.7715 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 27s 14s/step - loss: 0.7823 - accuracy: 0.5000 - val_loss: 0.7511 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 29s 11s/step - loss: 0.7191 - accuracy: 0.5152 - val_loss: 0.6964 - val_accuracy: 0.4545\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 30s 15s/step - loss: 0.6489 - accuracy: 0.5455 - val_loss: 0.7018 - val_accuracy: 0.4697\n"
     ]
    }
   ],
   "source": [
    "# Calculate steps_per_epoch and validation_steps\n",
    "steps_per_epoch_train = train_generator.samples // batch_size\n",
    "steps_per_epoch_valid = valid_generator.samples // batch_size\n",
    "steps_per_epoch_test = test_generator.samples // batch_size\n",
    "\n",
    "epochs = 10\n",
    "# Add 1 extra step if there are remaining samples not included in batches\n",
    "if train_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_train += 1\n",
    "if valid_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_valid += 1\n",
    "if test_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_test += 1\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=steps_per_epoch_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3c3cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 15s 4s/step - loss: 0.6926 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=steps_per_epoch_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b554f86e",
   "metadata": {
    "id": "AbwhUtUgq_16"
   },
   "source": [
    "Fine tune CNN model - doubling number of epochs to 20, reducing steps size by half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8de9312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 28s 28s/step - loss: 0.6440 - accuracy: 0.6471 - val_loss: 0.7038 - val_accuracy: 0.5156\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 27s 20s/step - loss: 0.6187 - accuracy: 0.6875 - val_loss: 0.7445 - val_accuracy: 0.4844\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 22s 21s/step - loss: 0.6195 - accuracy: 0.7059 - val_loss: 0.7198 - val_accuracy: 0.5312\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 21s 14s/step - loss: 0.5787 - accuracy: 0.7353 - val_loss: 0.7408 - val_accuracy: 0.4844\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 27s 20s/step - loss: 0.5657 - accuracy: 0.7344 - val_loss: 0.7410 - val_accuracy: 0.5156\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 21s 14s/step - loss: 0.5634 - accuracy: 0.7647 - val_loss: 0.7540 - val_accuracy: 0.5625\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 22s 15s/step - loss: 0.4980 - accuracy: 0.7647 - val_loss: 0.8475 - val_accuracy: 0.4844\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 29s 22s/step - loss: 0.4643 - accuracy: 0.7500 - val_loss: 0.8934 - val_accuracy: 0.5312\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 28s 21s/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.9662 - val_accuracy: 0.5156\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 22s 22s/step - loss: 0.2994 - accuracy: 0.9412 - val_loss: 1.0294 - val_accuracy: 0.5469\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 22s 22s/step - loss: 0.5094 - accuracy: 0.7353 - val_loss: 1.0709 - val_accuracy: 0.5156\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 21s 21s/step - loss: 0.2889 - accuracy: 0.9412 - val_loss: 1.1263 - val_accuracy: 0.4688\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 28s 21s/step - loss: 0.2854 - accuracy: 0.8906 - val_loss: 1.1347 - val_accuracy: 0.4688\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 28s 21s/step - loss: 0.2701 - accuracy: 0.9219 - val_loss: 1.2684 - val_accuracy: 0.4688\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 28s 21s/step - loss: 0.2473 - accuracy: 0.9375 - val_loss: 1.4475 - val_accuracy: 0.4688\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 22s 15s/step - loss: 0.1524 - accuracy: 0.9706 - val_loss: 1.6192 - val_accuracy: 0.4375\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 28s 21s/step - loss: 0.2130 - accuracy: 0.9531 - val_loss: 1.8274 - val_accuracy: 0.4375\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 28s 21s/step - loss: 0.1765 - accuracy: 0.9531 - val_loss: 2.0445 - val_accuracy: 0.4062\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 22s 22s/step - loss: 0.1585 - accuracy: 0.9118 - val_loss: 2.2094 - val_accuracy: 0.4844\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 21s 21s/step - loss: 0.1496 - accuracy: 0.9412 - val_loss: 2.5285 - val_accuracy: 0.3438\n"
     ]
    }
   ],
   "source": [
    "# Calculate steps_per_epoch and validation_steps\n",
    "steps_per_epoch_train = train_generator.samples // (batch_size * 2)\n",
    "steps_per_epoch_valid = valid_generator.samples // (batch_size * 2)\n",
    "steps_per_epoch_test = test_generator.samples // (batch_size * 2)\n",
    "\n",
    "epochs = 20\n",
    "# Add 1 extra step if there are remaining samples not included in batches\n",
    "if train_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_train += 1\n",
    "if valid_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_valid += 1\n",
    "if test_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_test += 1\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=steps_per_epoch_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c921d8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 14s 7s/step - loss: 1.9228 - accuracy: 0.4375\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=steps_per_epoch_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3cfd3",
   "metadata": {},
   "source": [
    "Use a model built from a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aed3665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17225924/17225924 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Use pretrained model\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define input image size expected by MobileNet\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Load the MobileNet model without the top classification layer\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze the layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom top layers for binary classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)  # Binary classification using sigmoid activation\n",
    "\n",
    "# Combine base model with custom top layers\n",
    "mobileModel = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "mobileModel.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fefa820b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 37s 15s/step - loss: 0.1501 - accuracy: 0.9394 - val_loss: 2.4773 - val_accuracy: 0.3939\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 29s 11s/step - loss: 0.1142 - accuracy: 0.9545 - val_loss: 2.5422 - val_accuracy: 0.3636\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 30s 12s/step - loss: 0.1430 - accuracy: 0.9242 - val_loss: 2.8153 - val_accuracy: 0.3636\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 30s 11s/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 3.5544 - val_accuracy: 0.4394\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 29s 14s/step - loss: 0.1189 - accuracy: 0.9545 - val_loss: 3.4511 - val_accuracy: 0.3636\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 30s 15s/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 3.2998 - val_accuracy: 0.3939\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 29s 11s/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 3.2265 - val_accuracy: 0.4394\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 30s 15s/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 3.4210 - val_accuracy: 0.4091\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 29s 11s/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 3.9300 - val_accuracy: 0.4242\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 29s 11s/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 4.4045 - val_accuracy: 0.4091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2355567ccd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "# Calculate steps_per_epoch and validation_steps\n",
    "steps_per_epoch_train = train_generator.samples // batch_size\n",
    "steps_per_epoch_valid = valid_generator.samples // batch_size\n",
    "epochs = 10\n",
    "# Add 1 extra step if there are remaining samples not included in batches\n",
    "if train_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_train += 1\n",
    "if valid_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_valid += 1\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=steps_per_epoch_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b50b4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 15s 4s/step - loss: 0.7903 - accuracy: 0.5152\n",
      "Test Loss: 0.7903\n",
      "Test Accuracy: 51.52%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "loss, accuracy = mobileModel.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e7e4bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 28s 21s/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 4.8190 - val_accuracy: 0.4062\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 28s 21s/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 4.8598 - val_accuracy: 0.4219\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 21s 14s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 5.0912 - val_accuracy: 0.4219\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 21s 14s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 5.5061 - val_accuracy: 0.4062\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 22s 21s/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 5.5496 - val_accuracy: 0.4062\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 22s 15s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.6877 - val_accuracy: 0.4375\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 22s 21s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 6.1183 - val_accuracy: 0.3906\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 21s 21s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.9494 - val_accuracy: 0.3750\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 21s 21s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 6.1947 - val_accuracy: 0.3906\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 22s 21s/step - loss: 6.6579e-04 - accuracy: 1.0000 - val_loss: 6.0513 - val_accuracy: 0.4062\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 22s 22s/step - loss: 7.7465e-04 - accuracy: 1.0000 - val_loss: 6.6259 - val_accuracy: 0.3750\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 28s 21s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.2911 - val_accuracy: 0.3906\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 21s 14s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.4865 - val_accuracy: 0.3906\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 27s 20s/step - loss: 8.0661e-04 - accuracy: 1.0000 - val_loss: 6.5897 - val_accuracy: 0.3906\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 21s 14s/step - loss: 8.3116e-04 - accuracy: 1.0000 - val_loss: 6.7501 - val_accuracy: 0.3906\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 21s 14s/step - loss: 2.8858e-04 - accuracy: 1.0000 - val_loss: 6.7987 - val_accuracy: 0.3906\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 22s 21s/step - loss: 8.1823e-04 - accuracy: 1.0000 - val_loss: 6.3472 - val_accuracy: 0.4062\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 22s 15s/step - loss: 3.5970e-04 - accuracy: 1.0000 - val_loss: 6.7611 - val_accuracy: 0.3750\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 22s 21s/step - loss: 6.6043e-04 - accuracy: 1.0000 - val_loss: 6.4178 - val_accuracy: 0.3906\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 21s 14s/step - loss: 4.5458e-04 - accuracy: 1.0000 - val_loss: 6.9436 - val_accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "# Fine tune the pretrained model\n",
    "\n",
    "# Calculate steps_per_epoch and validation_steps\n",
    "steps_per_epoch_train = train_generator.samples // (batch_size * 2)\n",
    "steps_per_epoch_valid = valid_generator.samples // (batch_size * 2)\n",
    "epochs = 20\n",
    "# Add 1 extra step if there are remaining samples not included in batches\n",
    "if train_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_train += 1\n",
    "if valid_generator.samples % batch_size != 0:\n",
    "    steps_per_epoch_valid += 1\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=steps_per_epoch_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d13f9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 14s 4s/step - loss: 0.7903 - accuracy: 0.5152\n",
      "Test Loss: 0.7903\n",
      "Test Accuracy: 51.52%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "loss, accuracy = mobileModel.evaluate(test_generator)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "730e6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "\n",
    "images_to_predict_dir = \"predict\"\n",
    "\n",
    "def predict_images_in_folder(model, folder_path):\n",
    "    predictions = []\n",
    "    image_paths = []\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(('.JPG')):\n",
    "                img_path = os.path.join(root, file)\n",
    "                image_paths.append(img_path)\n",
    "                prediction = predict_image(model, img_path)\n",
    "                predictions.append(prediction)\n",
    "    return image_paths, predictions\n",
    "\n",
    "# Function to predict a single image\n",
    "def predict_image(model, img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    if prediction < 0.5:\n",
    "        return \"Healthy\"\n",
    "    else:\n",
    "        return \"Unhealthy\"\n",
    "\n",
    "image_paths, predictions = predict_images_in_folder(model, images_to_predict_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05b5fdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x0 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_images = len(image_paths)\n",
    "num_cols = 5\n",
    "num_rows = -(-num_images // num_cols)  # Ceiling division\n",
    "\n",
    "plt.figure(figsize=(15, 3 * num_rows))\n",
    "for i, (img_path, prediction) in enumerate(zip(image_paths, predictions)):\n",
    "    plt.subplot(num_rows, num_cols, i + 1)\n",
    "    img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{os.path.basename(img_path)}\\nPrediction: {prediction}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984603e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
